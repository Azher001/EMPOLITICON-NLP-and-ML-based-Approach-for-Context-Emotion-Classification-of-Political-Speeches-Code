{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b49e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv(\"Dataset_PreProcessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import LongformerModel, AutoTokenizer\n",
    "\n",
    "model = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "for i in trange(len(dfTrain['Text_of_Speech'])):\n",
    "\n",
    "    input_ids = torch.tensor(tokenizer.encode(dfTrain['Text_of_Speech'][i])).unsqueeze(0)  # batch of size 1\n",
    "    \n",
    "    attention_mask = torch.ones(\n",
    "\n",
    "        input_ids.shape, dtype=torch.long, device=input_ids.device\n",
    "\n",
    "    )  # initialize to local attention\n",
    "\n",
    "    global_attention_mask = torch.zeros(\n",
    "\n",
    "        input_ids.shape, dtype=torch.long, device=input_ids.device\n",
    "\n",
    "    )  # initialize to global attention to be deactivated for all tokens\n",
    "\n",
    "    global_attention_mask[\n",
    "\n",
    "        :,\n",
    "\n",
    "        [\n",
    "\n",
    "            0,\n",
    "            -1\n",
    "\n",
    "        ],\n",
    "\n",
    "    ] = 1  # Set global attention to random tokens for the sake of this example\n",
    "\n",
    "    # Usually, set global attention based on the task. For example,\n",
    "\n",
    "    # classification: the <s> token\n",
    "\n",
    "    # QA: question tokens\n",
    "\n",
    "    # LM: potentially on the beginning of sentences and paragraphs\n",
    "\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n",
    "\n",
    "    sequence_output = outputs.last_hidden_state\n",
    "\n",
    "    pooled_output = outputs.pooler_output\n",
    "    x=pooled_output.detach().numpy()\n",
    "    embeddings.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f929339",
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDimentionalEmbedding =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79eec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for array in trange(len(embeddings)):\n",
    "    twoDimentionalEmbedding.append(embeddings[array][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twoDimentionalEmbedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames=[]\n",
    "for name in range(768):\n",
    "    columnNames.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6213a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainEmbedded = pd.DataFrame(twoDimentionalEmbedding, columns =columnNames, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a67351",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainEmbedded['Emotion'] = dfTrain['Context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainEmbedded['Context'] = dfTrain['Context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56953543",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainEmbedded.to_csv('Dataset_Longformer_Embedded.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
